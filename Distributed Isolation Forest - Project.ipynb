{"cells":[{"cell_type":"markdown","source":["# Distributed Isolation Forest\n\nIn this project we implemented a distributed versino of the Isolation Forest algorithm.\nWe compare our implementation to 3 other implementations:\n1. Sklearn-IForest - non distributed version of Isolation Forest\n2. spark-iforest - a distributed implementation of Isolation Forest\n3. SynapseML - distributed implementation by Microsoft\n\nWe compare the performance on the following datasets:\n1. Shuttle\n2. ForestCover\n3. Annthyroid\n4. Arrhythmia\n5. Mammography\n6. Http (KDDCUP99)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0da9e375-da48-461e-96f0-e21400cef63d","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Imports"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1f3e1ffc-3d07-4116-a271-166c75675a4c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import sys\nprint(\"\\n\".join(sys.path))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9062f1da-2c46-4759-bee1-c54841ae9927","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/databricks/python_shell/scripts\n/local_disk0/spark-90c0bb8b-eb54-4d38-9b69-6a23529895de/userFiles-a0812170-c3f3-4234-869d-fbe887f35900/addedFile2372871097350889815com_microsoft_azure_synapseml_vw_2_12_0_10_2-81557.jar\n/local_disk0/spark-90c0bb8b-eb54-4d38-9b69-6a23529895de/userFiles-a0812170-c3f3-4234-869d-fbe887f35900/addedFile1755398803738913152com_microsoft_azure_synapseml_opencv_2_12_0_10_2-d58bb.jar\n/local_disk0/spark-90c0bb8b-eb54-4d38-9b69-6a23529895de/userFiles-a0812170-c3f3-4234-869d-fbe887f35900/addedFile364942136124539941com_microsoft_azure_synapseml_lightgbm_2_12_0_10_2-26d77.jar\n/local_disk0/spark-90c0bb8b-eb54-4d38-9b69-6a23529895de/userFiles-a0812170-c3f3-4234-869d-fbe887f35900/addedFile8584233862606803279com_microsoft_azure_synapseml_deep_learning_2_12_0_10_2-35ed1.jar\n/local_disk0/spark-90c0bb8b-eb54-4d38-9b69-6a23529895de/userFiles-a0812170-c3f3-4234-869d-fbe887f35900/addedFile6972968937420700704com_microsoft_azure_synapseml_cognitive_2_12_0_10_2-799f1.jar\n/local_disk0/spark-90c0bb8b-eb54-4d38-9b69-6a23529895de/userFiles-a0812170-c3f3-4234-869d-fbe887f35900/addedFile807369118888474763com_microsoft_azure_synapseml_core_2_12_0_10_2-3c0a2.jar\n/local_disk0/spark-90c0bb8b-eb54-4d38-9b69-6a23529895de/userFiles-a0812170-c3f3-4234-869d-fbe887f35900\n/databricks/spark/python\n/databricks/spark/python/lib/py4j-0.10.9.5-src.zip\n/databricks/jars/spark--driver--driver-spark_3.3_2.12_deploy.jar\n/databricks/python_shell\n/usr/lib/python39.zip\n/usr/lib/python3.9\n/usr/lib/python3.9/lib-dynload\n\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-1a920015-ecad-4842-afc9-e179f61f7418/lib/python3.9/site-packages\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages\n/databricks/python/lib/python3.9/site-packages\n/usr/local/lib/python3.9/dist-packages\n/usr/lib/python3/dist-packages\n/databricks/python/lib/python3.9/site-packages/IPython/extensions\n/root/.ipython\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["/databricks/python_shell/scripts\n/local_disk0/spark-90c0bb8b-eb54-4d38-9b69-6a23529895de/userFiles-a0812170-c3f3-4234-869d-fbe887f35900/addedFile2372871097350889815com_microsoft_azure_synapseml_vw_2_12_0_10_2-81557.jar\n/local_disk0/spark-90c0bb8b-eb54-4d38-9b69-6a23529895de/userFiles-a0812170-c3f3-4234-869d-fbe887f35900/addedFile1755398803738913152com_microsoft_azure_synapseml_opencv_2_12_0_10_2-d58bb.jar\n/local_disk0/spark-90c0bb8b-eb54-4d38-9b69-6a23529895de/userFiles-a0812170-c3f3-4234-869d-fbe887f35900/addedFile364942136124539941com_microsoft_azure_synapseml_lightgbm_2_12_0_10_2-26d77.jar\n/local_disk0/spark-90c0bb8b-eb54-4d38-9b69-6a23529895de/userFiles-a0812170-c3f3-4234-869d-fbe887f35900/addedFile8584233862606803279com_microsoft_azure_synapseml_deep_learning_2_12_0_10_2-35ed1.jar\n/local_disk0/spark-90c0bb8b-eb54-4d38-9b69-6a23529895de/userFiles-a0812170-c3f3-4234-869d-fbe887f35900/addedFile6972968937420700704com_microsoft_azure_synapseml_cognitive_2_12_0_10_2-799f1.jar\n/local_disk0/spark-90c0bb8b-eb54-4d38-9b69-6a23529895de/userFiles-a0812170-c3f3-4234-869d-fbe887f35900/addedFile807369118888474763com_microsoft_azure_synapseml_core_2_12_0_10_2-3c0a2.jar\n/local_disk0/spark-90c0bb8b-eb54-4d38-9b69-6a23529895de/userFiles-a0812170-c3f3-4234-869d-fbe887f35900\n/databricks/spark/python\n/databricks/spark/python/lib/py4j-0.10.9.5-src.zip\n/databricks/jars/spark--driver--driver-spark_3.3_2.12_deploy.jar\n/databricks/python_shell\n/usr/lib/python39.zip\n/usr/lib/python3.9\n/usr/lib/python3.9/lib-dynload\n\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-1a920015-ecad-4842-afc9-e179f61f7418/lib/python3.9/site-packages\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages\n/databricks/python/lib/python3.9/site-packages\n/usr/local/lib/python3.9/dist-packages\n/usr/lib/python3/dist-packages\n/databricks/python/lib/python3.9/site-packages/IPython/extensions\n/root/.ipython\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\nfrom sklearn import metrics\nfrom DIForest import DIForest\nimport time"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"31a166a1-ef7d-48d7-ae66-d5155a37568b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)\n\u001B[0;32m<command-3701505335330571>\u001B[0m in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeature\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mVectorAssembler\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mDIForest\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mDIForest\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/python_shell/dbruntime/PythonPackageImportsInstrumentation/__init__.py\u001B[0m in \u001B[0;36mimport_patch\u001B[0;34m(name, globals, locals, fromlist, level)\u001B[0m\n\u001B[1;32m    169\u001B[0m             \u001B[0;31m# Import the desired module. If you’re seeing this while debugging a failed import,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    170\u001B[0m             \u001B[0;31m# look at preceding stack frames for relevant error information.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 171\u001B[0;31m             \u001B[0moriginal_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpython_builtin_import\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mglobals\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlocals\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfromlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    172\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    173\u001B[0m             \u001B[0mis_root_import\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mthread_local\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_nest_level\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'DIForest'","errorSummary":"<span class='ansi-red-fg'>ModuleNotFoundError</span>: No module named 'DIForest'","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)\n\u001B[0;32m<command-3701505335330571>\u001B[0m in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeature\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mVectorAssembler\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mDIForest\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mDIForest\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/python_shell/dbruntime/PythonPackageImportsInstrumentation/__init__.py\u001B[0m in \u001B[0;36mimport_patch\u001B[0;34m(name, globals, locals, fromlist, level)\u001B[0m\n\u001B[1;32m    169\u001B[0m             \u001B[0;31m# Import the desired module. If you’re seeing this while debugging a failed import,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    170\u001B[0m             \u001B[0;31m# look at preceding stack frames for relevant error information.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 171\u001B[0;31m             \u001B[0moriginal_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpython_builtin_import\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mglobals\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlocals\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfromlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    172\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    173\u001B[0m             \u001B[0mis_root_import\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mthread_local\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_nest_level\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'DIForest'"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Utils"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ff675971-dae5-49e4-a9dd-b6377a08da1a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def evaluate_model(model_name, y_true, y_pred, y_score):\n    print(\"Accuracy Score :\")\n    print(metrics.accuracy_score(y_true, y_pred))\n    print()\n    \n    print(\"Classification Report :\")\n    print(metrics.classification_report(y_true, y_pred))\n    print()\n    \n    print(\"Confusion Matrix:\")\n    print(metrics.confusion_matrix(y_true, y_pred))\n    print()\n    \n    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score)\n    auc = metrics.roc_auc_score(y_true, y_score)\n    \n    plt.subplots(1, figsize=(10,10))\n    plt.title(f'{model_name}, AUC={auc}')\n    plt.plot(fpr, tpr)\n    plt.plot([0, 1], ls=\"--\")\n    plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"828c75ce-9c53-4c39-a509-5c2168768a60","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["## Shuttle Dataset"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c939be90-fd6a-4241-bed8-02286f0b1a8d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["data = spark.read.table(\"hive_metastore.default.shuttle\")\ndata.printSchema()\n\nsamples_count = data.count()\noutliers_count = data.where(data[\"Y\"] == 1).count()\n\nprint(\"Count: \", samples_count)\nprint(\"Outliers: \", outliers_count)\nprint(\"Outliers percentage: \", outliers_count * 100 / samples_count, \"%\")\n\ninput_cols=[\"attr1\", \"attr2\", \"attr3\", \"attr4\", \"attr5\", \"attr6\", \"attr7\", \"attr8\", \"attr9\"]\n\nassembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\")\ndata = assembler.transform(data)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a0c2cef6-3bfa-4cc2-a238-38dfee518f39","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["### Our implementation"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c338a986-3151-4238-bded-763135cfdf8b","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["start_time = time.time()\n\ndis_model = DIForest(100, 256).fit(spark, data)\npredictions = dis_model.transform(spark, data)\n\net = time.time()\n\nelapsed_time = et - st\nprint('Execution time:', elapsed_time, 'seconds')\n\nevaluate_model(\"DISForest\", predictions_df[\"Y\"], predictions_df[\"prediction\"], predictions_df[\"anomalyScore\"])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0e97ac1c-366c-4500-89ac-49f72f073b04","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Distributed Isolation Forest - Project","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3701505335330562}},"nbformat":4,"nbformat_minor":0}
